# -*- coding: utf-8 -*-
"""vgg_face_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155DpJ_756FDztY5s6OX5EYBAKWyq9lXV
"""
import tensorflow as tf
from tensorflow.keras.applications import VGG16, ResNet50V2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D
from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop, Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Set GPU options
gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)
session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))

# VGG was designed to work on 224 x 224 pixel input images sizes
img_rows, img_cols = 224, 224 

# Re-loads the VGG model without the top or FC layers
vgg = ResNet50V2(weights = 'imagenet', 
                 include_top = False, 
                 input_shape = (img_rows, img_cols, 3))

# Here we freeze the last 4 layers 
# Layers are set to trainable as True by default
for layer in vgg.layers:
    layer.trainable = False
    
# Let's print our layers 
for (i,layer) in enumerate(vgg.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

def Fc(bottom_model, num_classes):
    """creates the top or head of the model that will be 
    placed ontop of the bottom layers"""

    top_model = bottom_model.output
    top_model = GlobalAveragePooling2D()(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(512,activation='relu')(top_model)
    top_model = Dense(num_classes,activation='softmax')(top_model)
    return top_model


# Set our class number to 3 (Young, Middle, Old)
num_classes = 5

FC_Head = Fc(vgg, num_classes)

model = Model(inputs = vgg.input, outputs = FC_Head)

print(model.summary())

train_data_dir = "./DataSetToSend/"
# validation_data_dir = '/content/drive/My Drive/image_dataset/validate/'

# Let's use some data augmentaiton 
train_datagen = ImageDataGenerator(
      validation_split=0.2,
      rescale=1./255,
      rotation_range=45,
      width_shift_range=0.4,
      height_shift_range=0.4,
      zoom_range=0.6,
      horizontal_flip=True,
      fill_mode='nearest')
 
validation_datagen = ImageDataGenerator(rescale=1./255)
 
# set our batch size (typically on most mid tier systems we'll use 16-32)
batch_size = 64
 
train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        subset="training",
        target_size=(img_rows, img_cols),
        batch_size=batch_size,
        seed=42,
        color_mode='grayscale',
        class_mode='categorical')

print("#####################:")
print(train_generator.class_indices)
 
validation_generator = train_datagen.flow_from_directory(
        train_data_dir,
        subset="validation",
        target_size=(img_rows, img_cols),
        batch_size=batch_size,
        color_mode='grayscale',
        seed=42,
        class_mode='categorical')

checkpoint = ModelCheckpoint("face_vgg.h5",
                             monitor="val_loss",
                             mode="min",
                             save_best_only = True,
                             verbose=1)

earlystop = EarlyStopping(monitor = 'val_loss', 
                          min_delta = 0, 
                          patience = 3,
                          verbose = 1,
                          restore_best_weights = True)

# we put our call backs into a callback list
callbacks = [earlystop, checkpoint]
# We use a very small learning rate 
model.compile(loss = 'categorical_crossentropy',
              optimizer = RMSprop(lr = 0.001),
              metrics = ['accuracy'])
# Enter the number of training and validation samples here
nb_train_samples = 200
nb_validation_samples = 200
# We only train 50 EPOCHS
epochs = 20
batch_size = 64
history = model.fit(
    train_generator,
    # steps_per_epoch = nb_train_samples // batch_size,
    epochs = epochs,
    callbacks = callbacks,
    validation_data = validation_generator)
    # validation_steps = nb_validation_samples // batch_size)

#Fine Tune
vgg.trainable = True
adam = Adam(learning_rate=0.0001)

#recompile model
model.compile(loss = 'categorical_crossentropy',
              optimizer = adam,
              metrics = ['accuracy'])

len(model.trainable_variables)

for (i,layer) in enumerate(vgg.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

fine_tune_epochs = 10
total_epochs = fine_tune_epochs + epochs
# total_epochs =  initial_epochs + fine_tune_epochs
model.summary()

history_fine = model.fit(train_generator,
                        epochs=total_epochs,
                        initial_epoch = history.epoch[-1],
                        validation_data=validation_generator)

epochs_range = range(epochs)

history = history_fine
# Visualizing results
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
